{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c359607-1e88-4ae9-b8b5-c193bc632a6a",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a25c4e-623b-4713-8989-d697b22eb7d9",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import expr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e14245-ebec-4138-b91e-98f25afafa4f",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "# Read historical customer churn data from silver catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65683c5-dfa9-4796-a48f-88e9e6b88708",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "training_data = spark.read.table(\"silver.historical.customers\")\n",
    "# drop non signifcant column\n",
    "training_data = training_data.drop(\"year\", \"sentimentScore_str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd39e2-b34f-4d6a-b051-ca6eb1b09fc3",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "# Process categorical and numeric attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5625325-a21a-48ab-b2dd-a38505afc138",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "categorical_cols = [\"gender\", \"partner\", \"dependents\", \"phoneservice\", \"multiplelines\", \"internetservice\", \"onlinesecurity\", \"onlinebackup\", \"deviceprotection\", \"techsupport\", \"streamingtv\", \"streamingmovies\", \"contract\", \"paperlessbilling\", \"paymentmethod\"]\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=c, outputCol=c + \"_idx\", handleInvalid=\"skip\")\n",
    "    for c in categorical_cols\n",
    "]\n",
    "encoders = [OneHotEncoder(inputCol=c + \"_idx\", outputCol=c + \"_vec\") for c in categorical_cols]\n",
    "\n",
    "# Numerical columns\n",
    "numeric_cols = [\"tenure\", \"monthlycharges\", \"totalcharges\", \"sentimentScore\"]\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[c + \"_vec\" for c in categorical_cols] + numeric_cols,\n",
    "    outputCol=\"features_raw\"\n",
    ")\n",
    "\n",
    "# Scale numerical features (optional but good practice)\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee5f724-7402-46fd-8e41-8877a5a112d7",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "# Set up Logistic Regression model within a Pipeline in Spark ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338bc21-2755-44bd-89ce-1ef30b515ca2",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"churn\")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13048b91-3ad5-4c78-a356-9e0352663ff3",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "# Split training data into train and test and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db514935-3550-4306-b4ab-bde317fa1de3",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "train, test = training_data.randomSplit([0.8, 0.2], seed=42)\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892ef5d5-0447-4a54-9a38-9dcbbf002c26",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "# Predict customer churn using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5eba03-1ea5-4215-9913-ac7795a1bd19",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "predictions = model.transform(test)\n",
    "\n",
    "# Keep customer_id with predictions\n",
    "result = predictions.select(\"customerid\", \"probability\", \"prediction\", \"churn\")\n",
    "\n",
    "result.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cebcedd-1ae0-4df5-a180-6e8f1ffb7c7c",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "# Evaluate the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af7f092-fc7a-4813-964f-b3915f50301d",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "# Extract probability and label\n",
    "scoreAndLabels = predictions.select(\"probability\", \"churn\") \\\n",
    "    .rdd.map(lambda row: (float(row.probability[1]), float(row.churn)))\n",
    "\n",
    "metrics = BinaryClassificationMetrics(scoreAndLabels)\n",
    "\n",
    "print(\"Accuracy: \", round(metrics.areaUnderROC*100 , 1), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067aa9f6-97cf-44b5-bed2-f17f732d7427",
   "metadata": {
    "type": "markdown"
   },
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36380f-834b-4733-a35a-a5b05c3ffbe5",
   "metadata": {
    "type": "python"
   },
   "outputs": [],
   "source": [
    "path = \"/Workspace/model/customer_churn/ml_model\"\n",
    "model.write().overwrite().save(path)\n",
    "print(\"Churn Prediction model saved at: \" + path)"
   ]
  }
 ],
 "metadata": {
  "Last_Active_Cell_Index": 15,
  "kernelspec": {
   "name": "notebook"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python"
  },
  "title": "Train a churn prediction model on cleansed historical data"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
