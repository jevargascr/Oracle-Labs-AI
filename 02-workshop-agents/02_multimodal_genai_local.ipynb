{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d51598-0bd2-4a73-9f2d-1d544d46c74a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  Laboratorio Multimodal con Oracle Generative AI Inference\n",
    "\n",
    "## Introducci贸n\n",
    "\n",
    "En este laboratorio aprender谩s a utilizar el **servicio Oracle Generative AI Inference** para realizar una interacci贸n **multimodal**: enviar texto junto con una imagen a un modelo de lenguaje de OCI y recibir una respuesta generada de manera contextual.\n",
    "\n",
    "El objetivo es demostrar, de forma pr谩ctica y simple, c贸mo **integrar capacidades de visi贸n y lenguaje natural (VLM)** dentro de un flujo de Python utilizando el SDK oficial de Oracle.\n",
    "\n",
    "A trav茅s de este ejemplo podr谩s:\n",
    "\n",
    "* Convertir una imagen local en una cadena Base64 v谩lida para el modelo.\n",
    "* Enviar un mensaje tipo *chat* que combina texto e imagen.\n",
    "* Obtener la descripci贸n generada por el modelo directamente desde OCI.\n",
    "* Comprender la estructura de objetos `ChatDetails`, `GenericChatRequest` y `Message` dentro del SDK.\n",
    "\n",
    "## Requisitos previos\n",
    "\n",
    "Antes de ejecutar el laboratorio, aseg煤rate de contar con:\n",
    "\n",
    "* Un **modelo Generative AI** disponible en tu tenancy (modalidad *On-Demand* o *Deployment*).\n",
    "* Credenciales configuradas en tu archivo `~/.oci/config`. (configurado previamente en el lab01)\n",
    "* Variables definidas:\n",
    "\n",
    "  ```python\n",
    "  ENDPOINT = \"https://inference.generativeai.<region>.oci.oraclecloud.com\" # NO Modificar\n",
    "  MODEL_ID = \"<OCID_DEL_MODELO>\" # NO Modificar\n",
    "  COMPARTMENT_ID = \"<OCID_DEL_COMPARTMENT>\" # Modificar\n",
    "  ```\n",
    "* Librer铆as instaladas:\n",
    "\n",
    "  ```bash\n",
    "  pip install oci\n",
    "  ```\n",
    "\n",
    "## Objetivo del ejemplo\n",
    "\n",
    "Enviar una imagen junto con una instrucci贸n textual para que el modelo describa su contenido, demostrando el potencial de la IA generativa en **aplicaciones con comprensi贸n visual y textual**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a00f00e-5890-489b-ab64-a8e732d8a35b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Multimodal chat (imagen + texto) en OCI Generative AI---\n",
    "\n",
    "import os, json, base64, mimetypes\n",
    "import oci\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730462e9-5ad0-4c24-8d63-caa8be39ce47",
   "metadata": {},
   "source": [
    "## Debemos actualizar los datos del compartment para la ejecuci贸n del c贸digo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f6b105-5e40-4c3a-afcf-deb95f09af30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Configuraci贸n base ===\n",
    "CONFIG_PROFILE = \"DEFAULT\"\n",
    "config = oci.config.from_file(os.path.expanduser(\"~/.oci/config\"), CONFIG_PROFILE)\n",
    "config[\"region\"] = \"us-chicago-1\"\n",
    "\n",
    "##datos actualizar\n",
    "COMPARTMENT_ID = \"ocid1.compartment.oc1..\"\n",
    "ENDPOINT = \"https://inference.generativeai.us-chicago-1.oci.oraclecloud.com\"\n",
    "\n",
    "MODEL_ID = \"ocid1.generativeaimodel.oc1.us-chicago-1.amaaaaaask7dceyayjawvuonfkw2ua4bob4rlnnlhs522pafbglivtwlfzta\"\n",
    "assert \".oc1.us-chicago-1.\" in MODEL_ID, \"El model_id debe ser de la regi贸n us-chicago-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976a2ce-dccb-49fe-b74c-9aca2cd1e1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === Utilidad: convertir imagen local a data URL base64 ===\n",
    "def image_to_data_url(path: str) -> str:\n",
    "    mime = mimetypes.guess_type(path)[0] or \"image/jpeg\"\n",
    "    with open(path, \"rb\") as f:\n",
    "        b64 = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return f\"data:{mime};base64,{b64}\"\n",
    "\n",
    "# Ruta de tu imagen local\n",
    "IMG_PATH = \"demo-image.jpeg\"\n",
    "PROMPT = \"Describe brevemente lo que ves en la imagen.\"\n",
    "\n",
    "# Prepara contenidos multimodales\n",
    "from oci.generative_ai_inference import GenerativeAiInferenceClient\n",
    "from oci.generative_ai_inference.models import (\n",
    "    ChatDetails,\n",
    "    OnDemandServingMode,\n",
    "    GenericChatRequest,\n",
    "    BaseChatRequest,\n",
    "    Message,\n",
    "    TextContent,\n",
    "    ImageContent,\n",
    "    ImageUrl,\n",
    ")\n",
    "\n",
    "# Imagen como data URL (tambi茅n puedes usar una URL p煤blica HTTPS)\n",
    "img_data_url = image_to_data_url(IMG_PATH)\n",
    "\n",
    "image_url = ImageUrl(url=img_data_url)\n",
    "image_content = ImageContent(image_url=image_url)\n",
    "\n",
    "text_content = TextContent(text=PROMPT)\n",
    "\n",
    "user_message = Message(role=\"USER\", content=[text_content, image_content])\n",
    "\n",
    "chat_request = GenericChatRequest(\n",
    "    api_format=BaseChatRequest.API_FORMAT_GENERIC,\n",
    "    messages=[user_message],\n",
    "    max_tokens=400,\n",
    "    temperature=0.4,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "chat_details = ChatDetails(\n",
    "    serving_mode=OnDemandServingMode(model_id=MODEL_ID),\n",
    "    chat_request=chat_request,\n",
    "    compartment_id=COMPARTMENT_ID,\n",
    ")\n",
    "\n",
    "client = GenerativeAiInferenceClient(config=config, service_endpoint=ENDPOINT)\n",
    "resp = client.chat(chat_details)\n",
    "\n",
    "# Extrae y muestra el texto de la respuesta\n",
    "choices = resp.data.chat_response.choices\n",
    "if choices:\n",
    "    parts = choices[0].message.content\n",
    "    texto = \"\\n\".join(getattr(p, \"text\", \"\") for p in parts if hasattr(p, \"text\"))\n",
    "    print(\"\\n=== RESPUESTA ===\\n\", texto.strip())\n",
    "else:\n",
    "    print(\"No se gener贸 respuesta.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ea6da7-4773-48ee-8f45-1f9a8b4febcb",
   "metadata": {},
   "source": [
    "## З Puntos adicionales: 隆Hazlo interactivo!\n",
    "\n",
    "Ahora que ya probaste el flujo b谩sico, puedes **subir una foto tuya o cualquier imagen divertida** para que el modelo la interprete y responda de forma contextual.\n",
    "\n",
    "1.  **Carga tu imagen local** (por ejemplo `selfie-divertida.jpeg` o cualquier imagen creativa).\n",
    "   Aseg煤rate de colocarla en la misma carpeta del notebook o ajustar la ruta:\n",
    "\n",
    "   ```python\n",
    "   IMG_PATH = \"selfie-divertida.jpeg\"\n",
    "   ```\n",
    "\n",
    "2.  **Formula preguntas abiertas** al modelo relacionadas con la imagen.\n",
    "   Por ejemplo:\n",
    "\n",
    "   ```python\n",
    "   PROMPT = \"\"\"\n",
    "   Observa la foto y dime qu茅 emociones transmite.\n",
    "   驴Qu茅 tipo de actividad parece estar realizando la persona?\n",
    "   驴Podr铆as generar una historia corta inspirada en la imagen?\n",
    "   \"\"\"\n",
    "   ```\n",
    "\n",
    "3.  **Ejecuta nuevamente la celda principal del chat**\n",
    "   Ver谩s c贸mo el modelo analiza tanto la imagen como el texto, generando respuestas personalizadas seg煤n el contenido visual.\n",
    "\n",
    "4.  **Experimenta con distintas instrucciones**:\n",
    "\n",
    "   * Descr铆beme el fondo de la foto con detalle.\n",
    "   * Imagina que esta imagen es parte de una pel铆cula, 驴c贸mo se llamar铆a?\n",
    "   * Convierte la escena en un poema corto.\n",
    "\n",
    "5.  **Objetivo final:** Comprender c贸mo los modelos multimodales pueden interpretar simult谩neamente informaci贸n visual y textual, y c贸mo esto se puede aplicar en contextos reales como **an谩lisis de im谩genes, storytelling, educaci贸n o generaci贸n de contenido creativo.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb119955-bf62-4923-9099-451e577d689b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
